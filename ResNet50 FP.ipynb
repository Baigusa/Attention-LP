{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c74fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from keras.layers import Conv2D,Reshape,GlobalAveragePooling2D,Multiply,Lambda, Activation,MaxPooling2D,Dense,Input,ZeroPadding2D,BatchNormalization,Add,AveragePooling2D,Flatten\n",
    "from keras.initializers import glorot_uniform\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import tempfile\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "from keras.layers import Conv2D,Reshape,BatchNormalization,GlobalAveragePooling2D,Multiply,Lambda, Activation,GlobalMaxPooling2D,Dense,Input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from matplotlib import pyplot as plt\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device=cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67597306",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_input(input_images):\n",
    "  input_images = input_images.astype('float32')\n",
    "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
    "  return output_ims\n",
    "train_X = preprocess_image_input(training_images)\n",
    "valid_X = preprocess_image_input(validation_images)\n",
    "#train_X=tf.image.resize(train_X,(,48))\n",
    "#valid_X=tf.image.resize(valid_X,(224,48))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fe2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d1a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d380d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer=glorot_uniform(seed =0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu') (X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer=glorot_uniform(seed =0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed =0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (32, 32, 3), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    resize = tf.keras.layers.UpSampling2D(size=(7,7))( X_input)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))( resize)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = GlobalAveragePooling2D()(X) \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "model=ResNet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flops_count(new_model):\n",
    "    total_flops = 0\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            #print(f'{layer.name}') \n",
    "            kernel_size = layer.kernel_size\n",
    "            input_channels = layer.input_shape[-1]\n",
    "            output_channels = layer.output_shape[-1]\n",
    "            height = layer.output_shape[1]\n",
    "            width = layer.output_shape[2]\n",
    "            flops = ((kernel_size[0] * kernel_size[1] * input_channels) * output_channels + output_channels) * height * width\n",
    "            total_flops += flops\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            input_neurons = layer.input_shape[-1]\n",
    "            output_neurons = layer.units\n",
    "            flops = (input_neurons * output_neurons) + output_neurons\n",
    "            total_flops += flops\n",
    "    return total_flops\n",
    "print(f'Model Flops: {flops_count(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b772852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "\n",
    "EPOCHS = 3\n",
    "history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ee185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy imagenet weights\n",
    "\n",
    "for layer, layer_res50 in zip(model.layers[2:],res50_model.layers[1:]):\n",
    "    weights_model = layer.get_weights()\n",
    "    weights_res50 = layer_res50.get_weights()\n",
    "        \n",
    "    if weights_model and weights_res50 and weights_model[0].shape == weights_res50[0].shape:\n",
    "        layer.set_weights(weights_res50)\n",
    "\n",
    "model.get_layer('res2a_branch1').set_weights(res50_model.get_layer('conv2_block1_0_conv').get_weights())\n",
    "model.get_layer('res2a_branch2c').set_weights(res50_model.get_layer('conv2_block1_3_conv').get_weights())\n",
    "model.get_layer( 'bn2a_branch1').set_weights(res50_model.get_layer('conv2_block1_0_bn').get_weights())\n",
    "model.get_layer('bn2a_branch2c').set_weights(res50_model.get_layer('conv2_block1_3_bn').get_weights())\n",
    "\n",
    "model.get_layer('res3a_branch1').set_weights(res50_model.get_layer('conv3_block1_0_conv').get_weights())\n",
    "model.get_layer('res3a_branch2c').set_weights(res50_model.get_layer('conv3_block1_3_conv').get_weights())\n",
    "model.get_layer( 'bn3a_branch1').set_weights(res50_model.get_layer('conv3_block1_0_bn').get_weights())\n",
    "model.get_layer('bn3a_branch2c').set_weights(res50_model.get_layer('conv3_block1_3_bn').get_weights())\n",
    "\n",
    "model.get_layer('res4a_branch1').set_weights(res50_model.get_layer('conv4_block1_0_conv').get_weights())\n",
    "model.get_layer('res4a_branch2c').set_weights(res50_model.get_layer('conv4_block1_3_conv').get_weights())\n",
    "model.get_layer( 'bn4a_branch1').set_weights(res50_model.get_layer('conv4_block1_0_bn').get_weights())\n",
    "model.get_layer('bn4a_branch2c').set_weights(res50_model.get_layer('conv4_block1_3_bn').get_weights())\n",
    "\n",
    "model.get_layer('res5a_branch1').set_weights(res50_model.get_layer('conv5_block1_0_conv').get_weights())\n",
    "model.get_layer('res5a_branch2c').set_weights(res50_model.get_layer('conv5_block1_3_conv').get_weights())\n",
    "model.get_layer( 'bn5a_branch1').set_weights(res50_model.get_layer('conv5_block1_0_bn').get_weights())\n",
    "model.get_layer('bn5a_branch2c').set_weights(res50_model.get_layer('conv5_block1_3_bn').get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model:')\n",
    "#print(model.get_layer('res5b_branch2a').get_weights())\n",
    "\n",
    "print(res50_model.get_layer('conv5_block2_1_conv').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# TRAINING THE CNN ON THE TRAIN/VALIDATION DATA\n",
    "#------------------------------------------------------------------------------\n",
    "from tensorflow.keras import optimizers\n",
    "# initiate SGD optimizer\n",
    "sgd = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return 0.001 * (0.5 ** (epoch // 20))\n",
    "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "#mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "Monitor=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',patience=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint('model.h5',monitor='val_accuracy',mode='max',save_best_only=True)\n",
    "]\n",
    "\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 1\n",
    "BS = 16\n",
    "  \n",
    "#history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[reduce_lr,Monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[reduce_lr,Monitor])\n",
    "baseline_model_loss, baseline_model_accuracy = model.evaluate(\n",
    "    valid_X, validation_labels, verbose=1)\n",
    "\n",
    "print('Baseline test loss:  accuracy:', baseline_model_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ad618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training weights for future use\n",
    "#model.save_weights('res50_cifar100_model.ckpt')\n",
    "model.save_weights('model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78968f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('res50_cifar100_model.ckpt')\n",
    "#model.load_weights('model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruned_ResNet50(pruning_percent):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    input_shape = (32, 32, 3)\n",
    "    classes = 100\n",
    "    pruning_percent=(pruning_percent/100)\n",
    "\n",
    "    stage_2_filters=[64-int(64*pruning_percent),64-int(64*pruning_percent),256-int(256*pruning_percent)]\n",
    "    stage_3_filters=[128-int(128*pruning_percent),128-int(128*pruning_percent),512-int(512*pruning_percent)]\n",
    "    stage_4_filters=[256-int(256*pruning_percent),256-int(256*pruning_percent),1024-int(1024*pruning_percent)]\n",
    "    stage_5_filters=[512-int(512*pruning_percent),512-int(512*pruning_percent),2048-int(2048*pruning_percent)]\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    resize = tf.keras.layers.UpSampling2D(size=(7,7))( X_input)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(resize)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = stage_2_filters, stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, stage_2_filters, stage=2, block='b')\n",
    "    X = identity_block(X, 3, stage_2_filters, stage=2, block='c')\n",
    "\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = stage_3_filters, stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, stage_3_filters, stage=3, block='b')\n",
    "    X = identity_block(X, 3, stage_3_filters, stage=3, block='c')\n",
    "    X = identity_block(X, 3, stage_3_filters, stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = stage_4_filters, stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, stage_4_filters, stage=4, block='b')\n",
    "    X = identity_block(X, 3, stage_4_filters, stage=4, block='c')\n",
    "    X = identity_block(X, 3, stage_4_filters, stage=4, block='d')\n",
    "    X = identity_block(X, 3, stage_4_filters, stage=4, block='e')\n",
    "    X = identity_block(X, 3, stage_4_filters, stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = stage_5_filters, stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, stage_5_filters, stage=5, block='b')\n",
    "    X = identity_block(X, 3, stage_5_filters, stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    # Create model\n",
    "    pruned_model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return pruned_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers import GroupNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ab691",
   "metadata": {},
   "source": [
    "# CBAM Resnet-50 cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam(inputs, ratio=16):\n",
    "    \n",
    "    \n",
    "    class GlobalStdPooling(tf.keras.layers.Layer):\n",
    "        def call(self, inputs):\n",
    "            # Calculate global average pooling\n",
    "            mean = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "            #max = tf.reduce_max(inputs, axis=[1, 2], keepdims=True) \n",
    "            #print('mean:')\n",
    "            #tf.print(max)\n",
    "            # Subtract the mean from each channel\n",
    "            centered_inputs = inputs - mean\n",
    "\n",
    "            # Square the centered differences\n",
    "            squared_diff = tf.square(centered_inputs)\n",
    "            #print(\"squared_diff:\")\n",
    "            #print(  squared_diff.shape)\n",
    "            # Calculate the standard deviation\n",
    "            std_dev = (tf.sqrt(tf.reduce_mean(squared_diff, axis=[1, 2], keepdims=True)+1e-5)) #epsilon=1e-5\n",
    "            #print('std:')\n",
    "            #tf.print(std_dev)\n",
    "            # Flatten the std_dev tensor\n",
    "            flattened_mean = tf.keras.layers.Flatten()( mean )\n",
    "            channel_std = tf.keras.layers.Flatten()(std_dev)\n",
    "            #tf.print(flattened_mean)\n",
    "            #tf.print(flattened_mean-2 )\n",
    "\n",
    "            return  channel_std\n",
    "    # Create CBAM block\n",
    "    x=inputs\n",
    "    x1 = GlobalAveragePooling2D()(x) \n",
    "    #x1 = GlobalStdPooling()(x) \n",
    "    #x1=p+q\n",
    "    #x1=Reshape((x.shape[-1],1))(x1)\n",
    "    x1 = Dense(units=x.shape[-1] // 16, activation='relu')(x1)\n",
    "    #x1=Conv1D(filters=1,kernel_size=3,padding='same',activation='sigmoid')(x1)\n",
    "    x1 = Dense(units=x.shape[-1], activation='relu')(x1)\n",
    "    #x1=Reshape((x.shape[-1],))(x1)\n",
    "    #x1=GroupNormalization(groups=4)(x1)\n",
    "\n",
    "    #x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = GlobalStdPooling()(x) \n",
    "    #x2=y+z \n",
    "    #x2=Reshape((x.shape[-1],1))(x2)\n",
    "    #x2=Conv1D(filters=1,kernel_size=3,padding='same',activation='sigmoid')(x2)\n",
    "    x2 = Dense(units=x.shape[-1] // 16, activation='relu')(x2)\n",
    "    x2 = Dense(units=x.shape[-1], activation='relu')(x2)\n",
    "    #x2=Reshape((x.shape[-1],))(x2)\n",
    "    #x2=GroupNormalization(groups=4)(x2)\n",
    "    #x2 = GlobalStdPooling()(x)\n",
    "    #y = GlobalAveragePooling2D()(x)\n",
    "\n",
    "\n",
    "    #x2=GroupNormalization(groups=4)(x2)\n",
    "    \n",
    "    features=x1+x2\n",
    "    features=Activation(\"sigmoid\")(features)\n",
    "    \n",
    "    excitation = Reshape((1, 1, x.shape[-1]))(features)\n",
    "    scale = Multiply()([x, excitation]) \n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cbam_identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X=cbam(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X=cbam(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    X=cbam(X)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #X=cbam(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03795e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X=cbam(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer=glorot_uniform(seed =0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu') (X)\n",
    "    \n",
    "    #CBAM\n",
    "    X=cbam(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer=glorot_uniform(seed =0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    X=cbam(X)\n",
    "    \n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed =0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    \n",
    "    X_shortcut=cbam(X_shortcut)\n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc37f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_ResNet50(input_shape = (32, 32, 3), classes = 100):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    resize = tf.keras.layers.UpSampling2D(size=(7,7))( X_input)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))( resize)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = cbam_convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = cbam_identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = cbam_identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    # Stage 3\n",
    "    X = cbam_convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = cbam_identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = cbam_identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = cbam_identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = cbam_convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = cbam_identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = cbam_identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = cbam_identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = cbam_identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = cbam_identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = cbam_convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = cbam_identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = cbam_identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = GlobalAveragePooling2D()(X) \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    # Create model\n",
    "    cbam_model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return cbam_model\n",
    "\n",
    "cbam_model=cbam_ResNet50() \n",
    "cbam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### weight copy resnet50 to cbam resnet50 #######\n",
    "\n",
    "# Create a dictionary to map layer names to their corresponding weights in model1\n",
    "model_layer_weights = {layer.name: layer.get_weights() for layer in model.layers}\n",
    "\n",
    "# Iterate through the layers of model2 and copy weights from model1 for layers with matching names\n",
    "for layer in cbam_model.layers:\n",
    "    if layer.name in model_layer_weights and layer.name!='Dense'and layer.get_weights(): \n",
    "        layer.set_weights(model_layer_weights[layer.name])\n",
    "\n",
    "#copy last dense layer weight\n",
    "        \n",
    "cbam_model.layers[-1].set_weights(model.layers[-1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e991a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### train cbam model ########\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return 0.001 * (0.5 ** (epoch // 10))\n",
    "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "# For a multi-class classification problem\n",
    "cbam_model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    " #Finetune\n",
    "\n",
    "history = cbam_model.fit(train_X, training_labels, epochs=35, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[reduce_lr ])\n",
    "\n",
    "#model evaluation\n",
    "model_loss, cbam_accuracy = cbam_model.evaluate(valid_X, validation_labels, verbose=1)\n",
    "print('cbam test accuracy:', cbam_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in cbam_model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8db577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bf746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_average_cbam(cbam_model):\n",
    "\n",
    "    activation_average=[]\n",
    "    for layer in cbam_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "        #if isinstance(layer, tf.keras.layers.Reshape) and (isinstance(cbam_model.layers[cbam_model.layers.index(layer)+1],Multiply)):\n",
    "            print(f'{layer.name} Done')\n",
    "            test_data=train_X[:1000] #only pick those sample which are correctly classified\n",
    "            true_labels =training_labels[:1000]\n",
    "            predictions = cbam_model.predict(test_data)\n",
    "            predicted_classes = np.argmax(predictions, axis=1)\n",
    "            true_labels = np.argmax(true_labels, axis=1)\n",
    "            correct_indices = np.where(predicted_classes == true_labels)[0]\n",
    "            correct_test_data = test_data[correct_indices]\n",
    "\n",
    "            # calculating activation for filter pruning\n",
    "\n",
    "            inputs=cbam_model.input\n",
    "            outputs=layer.output\n",
    "\n",
    "            activation_model=tf.keras.Model(inputs=inputs,outputs=outputs) # create new block for activation calculation\n",
    "            activation_SE=activation_model.predict(correct_test_data)\n",
    "\n",
    "            # calculate the average activation from the SE block, reshape layer is used so we squeeze the shape\n",
    "\n",
    "            acti_average=np.average(np.squeeze(activation_SE),axis=0)\n",
    "            activation_average.append(acti_average)\n",
    "    return activation_average \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pruning_using_activation_cbam(model, activation_average,prune_percent):\n",
    "    activation_average_index=0\n",
    "    for layer in model.layers[8:]: # except 1st conv\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            #print(layer.name)\n",
    "            weights = layer.get_weights()  # Get the weights of the layer\n",
    "            #filter pruning by observing activation\n",
    "            filter_activation_pruning=activation_average[activation_average_index]\n",
    "            #print(activation_average_index)\n",
    "            activation_average_index=activation_average_index+1   # Compute the L1-norm for each filter\n",
    "            num_prune = int(prune_percent * 0.01 * len(filter_activation_pruning))  # Determine the number of filters to prune\n",
    "            prune_indices = np.argsort(filter_activation_pruning)[:num_prune]  # Get the indices of the filters to prune\n",
    "            pruned_weights = weights[0].copy()  # Create a copy of the weights\n",
    "            pruned_weights[:, :, :, prune_indices] = 0  # Prune the filters by setting their weights to zero\n",
    "            layer.set_weights([pruned_weights, weights[1]])  # Set the new weights for the Conv2D layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8b158",
   "metadata": {},
   "source": [
    "# Cifar-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "#copy the first 6 layer weights\n",
    "model.load_weights('model.ckpt')\n",
    "#from tensorflow import keras\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "#model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "baseline_model_loss, baseline_model_accuracy = model.evaluate(\n",
    "        valid_X, validation_labels, verbose=1)\n",
    "\n",
    "print('Baseline test loss:  accuracy:', baseline_model_accuracy)\n",
    "\n",
    "prune_percent=[10,20,30,40,50,60,70,80]\n",
    "#prune_percent=[20,40]\n",
    "filter_pruned_model_accuracy=[]\n",
    "# first accuracy after x% weight pruning\n",
    "number_of_parameters_after_pruning=[]\n",
    "#filter_pruned_model_accuracy.append(baseline_model_accuracy)\n",
    "activation_average=activation_average_cbam(cbam_model)\n",
    "#print(activation_average)\n",
    "for i in range(8):\n",
    "    model.load_weights('model.ckpt')\n",
    "\n",
    "   \n",
    "    model=filter_pruning_using_activation_cbam(model,activation_average, prune_percent[i])\n",
    "    # For a multi-class classification problem\n",
    "    #model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    "     #Finetune\n",
    "    \n",
    "    #history = model.fit(train_X, training_labels, epochs=1, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[Filter_pruning_callback])\n",
    "     #model evaluation\n",
    "    \n",
    "    #baseline_model_loss, baseline_model_accuracy = model.evaluate(\n",
    "        #valid_X, validation_labels, verbose=1)\n",
    "\n",
    "    #print('pruned test   accuracy:', baseline_model_accuracy)\n",
    "       \n",
    "\n",
    "    pruned_model=pruned_ResNet50(prune_percent[i])\n",
    "    \n",
    "    pruned_model.summary()\n",
    "    \n",
    "    for layer, new_layer in zip(model.layers[:8], pruned_model.layers[:8]):\n",
    "        weights_model = layer.get_weights()\n",
    "        weights_res50 = new_layer.get_weights()\n",
    "\n",
    "        if weights_model and weights_res50 and weights_model[0].shape == weights_res50[0].shape:\n",
    "            new_layer.set_weights(weights_model)\n",
    "\n",
    "    conv_block_layer_name=['res2a_branch1','res3a_branch1','res4a_branch1','res5a_branch1']\n",
    "    count=1\n",
    "    previous_layer_input_channel=np.array([],dtype=bool)\n",
    "    #copy the rest weights\n",
    "    for layer, new_layer in zip(model.layers[8:], pruned_model.layers[8:]):\n",
    "        if isinstance(layer,Conv2D)and layer.name not in  conv_block_layer_name:\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2)) # check for any non zero value\n",
    "            #print(layer.name)\n",
    "            #print(non_zero_filters)\n",
    "            # Get the non-zero weights and biases\n",
    "            if count==1: # for first conv2D\n",
    "               non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "               new_model_weights= weights[0][:, :, :, non_zero_filters]\n",
    "               count+=1\n",
    "            else:\n",
    "                non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "                new_model_weights=non_zero_weights[:,:,previous_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            #print(layer.name)\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            if layer.name in ['res3a_branch2a','res4a_branch2a','res5a_branch2a']: #keep for conv block\n",
    "                #variable_name = layer.name + \"res3a_branch2a_layer_input_channel\"\n",
    "                if layer.name=='res3a_branch2a':\n",
    "                    res3a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res3a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "                \n",
    "                if layer.name=='res4a_branch2a':\n",
    "                    res4a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res4a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "                if layer.name=='res5a_branch2a':\n",
    "                    res5a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res5a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "               \n",
    "            #BN copy\n",
    "            next_layer_index = model.layers.index(layer) + 1\n",
    "            next_next_layer_index = model.layers.index(layer) + 2\n",
    "            if isinstance(model.layers[next_layer_index], BatchNormalization) or isinstance(model.layers[next_next_layer_index], BatchNormalization):\n",
    "               bn_layer = model.layers[next_layer_index] if isinstance(model.layers[next_layer_index], BatchNormalization) else model.layers[next_next_layer_index]\n",
    "               pruned_bn_layer = pruned_model.layers[next_layer_index] if isinstance(pruned_model.layers[next_layer_index], BatchNormalization) else pruned_model.layers[next_next_layer_index]\n",
    "               weights=bn_layer.get_weights()\n",
    "               bn_weights=[]\n",
    "               bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "               pruned_bn_layer.set_weights(bn_weights)\n",
    "\n",
    "            previous_layer_input_channel=non_zero_filters\n",
    "\n",
    "\n",
    "\n",
    "        #conv block weight copy ########## projection conv\n",
    "\n",
    "        if layer.name=='res2a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            new_model_weights= weights[0][:, :, :, non_zero_filters]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            #BN copy\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "        if layer.name=='res3a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters] #output channel\n",
    "            new_model_weights=non_zero_weights[:,:,res3a_branch2a_layer_input_channel,:]  #input channel\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "\n",
    "        if layer.name=='res4a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "            new_model_weights=non_zero_weights[:,:,res4a_branch2a_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "\n",
    "        if layer.name=='res5a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "            new_model_weights=non_zero_weights[:,:,res5a_branch2a_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "            \n",
    "    if isinstance(layer,Dense):\n",
    "        dense_weights=layer.get_weights()\n",
    "        new_dense_weight=dense_weights[0][previous_layer_input_channel]\n",
    "                #new_dense_bias=dense_weights[1][previous_layer_input_channel]\n",
    "        new_layer.set_weights([new_dense_weight,dense_weights[1]])\n",
    "\n",
    "    \n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return 0.001 * (0.5 ** (epoch // 10))\n",
    "    reduce_lr = LearningRateScheduler(lr_scheduler)\n",
    "    \n",
    "    \n",
    "    # For a multi-class classification problem\n",
    "    pruned_model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    "     #Finetune\n",
    "    \n",
    "    history = pruned_model.fit(train_X, training_labels, epochs=35, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[reduce_lr ])\n",
    "    \n",
    "    #model evaluation\n",
    "    model_loss, pruned_accuracy = pruned_model.evaluate(valid_X, validation_labels, verbose=1)\n",
    "    #print('Filter Pruned test accuracy:', pruned_accuracy)\n",
    "    filter_pruned_model_accuracy.append(pruned_accuracy)\n",
    "    print(filter_pruned_model_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Total number of parameters before pruning: {model.count_params()}\")\n",
    "    print(f\"Total number of parameters after pruning: {pruned_model.count_params()}\")\n",
    "    \n",
    "    number_of_parameters_after_pruning.append(pruned_model.count_params())\n",
    "    print(number_of_parameters_after_pruning)\n",
    "    print(f'Pruned percentage: {(1-(pruned_model.count_params()/model.count_params()))*100}')\n",
    "\n",
    "    del pruned_model\n",
    "    gc.collect() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44684247",
   "metadata": {},
   "outputs": [],
   "source": [
   
  },
  {
   "cell_type": "markdown",
   "id": "767cca30",
   "metadata": {},
   "source": [
    "# Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "#copy the first 6 layer weights\n",
    "model.load_weights('model.ckpt')\n",
    "#from tensorflow import keras\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "#model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "baseline_model_loss, baseline_model_accuracy = model.evaluate(\n",
    "        valid_X, validation_labels, verbose=1)\n",
    "\n",
    "print('Baseline test loss:  accuracy:', baseline_model_accuracy)\n",
    "\n",
    "prune_percent=[10,20,30,40,50,60,70,80]\n",
    "#prune_percent=[20,40]\n",
    "filter_pruned_model_accuracy=[]\n",
    "# first accuracy after x% weight pruning\n",
    "number_of_parameters_after_pruning=[]\n",
    "#filter_pruned_model_accuracy.append(baseline_model_accuracy)\n",
    "activation_average=activation_average_cbam(cbam_model)\n",
    "#print(activation_average)\n",
    "for i in range(8):\n",
    "    model.load_weights('model.ckpt')\n",
    "\n",
    "   \n",
    "    model=filter_pruning_using_activation_cbam(model,activation_average, prune_percent[i])\n",
    "    # For a multi-class classification problem\n",
    "    #model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    "     #Finetune\n",
    "    \n",
    "    #history = model.fit(train_X, training_labels, epochs=1, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[Filter_pruning_callback])\n",
    "     #model evaluation\n",
    "    \n",
    "    #baseline_model_loss, baseline_model_accuracy = model.evaluate(\n",
    "        #valid_X, validation_labels, verbose=1)\n",
    "\n",
    "    #print('pruned test   accuracy:', baseline_model_accuracy)\n",
    "       \n",
    "\n",
    "    pruned_model=pruned_ResNet50(prune_percent[i])\n",
    "    \n",
    "    pruned_model.summary()\n",
    "    \n",
    "    for layer, new_layer in zip(model.layers[:8], pruned_model.layers[:8]):\n",
    "        weights_model = layer.get_weights()\n",
    "        weights_res50 = new_layer.get_weights()\n",
    "\n",
    "        if weights_model and weights_res50 and weights_model[0].shape == weights_res50[0].shape:\n",
    "            new_layer.set_weights(weights_model)\n",
    "\n",
    "    conv_block_layer_name=['res2a_branch1','res3a_branch1','res4a_branch1','res5a_branch1']\n",
    "    count=1\n",
    "    previous_layer_input_channel=np.array([],dtype=bool)\n",
    "    #copy the rest weights\n",
    "    for layer, new_layer in zip(model.layers[8:], pruned_model.layers[8:]):\n",
    "        if isinstance(layer,Conv2D)and layer.name not in  conv_block_layer_name:\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2)) # check for any non zero value\n",
    "            #print(layer.name)\n",
    "            #print(non_zero_filters)\n",
    "            # Get the non-zero weights and biases\n",
    "            if count==1: # for first conv2D\n",
    "               non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "               new_model_weights= weights[0][:, :, :, non_zero_filters]\n",
    "               count+=1\n",
    "            else:\n",
    "                non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "                new_model_weights=non_zero_weights[:,:,previous_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            #print(layer.name)\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            if layer.name in ['res3a_branch2a','res4a_branch2a','res5a_branch2a']: #keep for conv block\n",
    "                #variable_name = layer.name + \"res3a_branch2a_layer_input_channel\"\n",
    "                if layer.name=='res3a_branch2a':\n",
    "                    res3a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res3a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "                \n",
    "                if layer.name=='res4a_branch2a':\n",
    "                    res4a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res4a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "                if layer.name=='res5a_branch2a':\n",
    "                    res5a_branch2a_layer_input_channel=np.array([],dtype=bool)\n",
    "                    res5a_branch2a_layer_input_channel=previous_layer_input_channel\n",
    "               \n",
    "            #BN copy\n",
    "            next_layer_index = model.layers.index(layer) + 1\n",
    "            next_next_layer_index = model.layers.index(layer) + 2\n",
    "            if isinstance(model.layers[next_layer_index], BatchNormalization) or isinstance(model.layers[next_next_layer_index], BatchNormalization):\n",
    "               bn_layer = model.layers[next_layer_index] if isinstance(model.layers[next_layer_index], BatchNormalization) else model.layers[next_next_layer_index]\n",
    "               pruned_bn_layer = pruned_model.layers[next_layer_index] if isinstance(pruned_model.layers[next_layer_index], BatchNormalization) else pruned_model.layers[next_next_layer_index]\n",
    "               weights=bn_layer.get_weights()\n",
    "               bn_weights=[]\n",
    "               bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "               pruned_bn_layer.set_weights(bn_weights)\n",
    "\n",
    "            previous_layer_input_channel=non_zero_filters\n",
    "\n",
    "\n",
    "\n",
    "        #conv block weight copy\n",
    "\n",
    "        if layer.name=='res2a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            new_model_weights= weights[0][:, :, :, non_zero_filters]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            #BN copy\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "        if layer.name=='res3a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters] #output channel\n",
    "            new_model_weights=non_zero_weights[:,:,res3a_branch2a_layer_input_channel,:]  #input channel\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "\n",
    "        if layer.name=='res4a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "            new_model_weights=non_zero_weights[:,:,res4a_branch2a_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "\n",
    "        if layer.name=='res5a_branch1':\n",
    "            weights=layer.get_weights()\n",
    "            non_zero_filters = np.any(weights[0], axis=(0, 1, 2))\n",
    "            non_zero_weights = weights[0][:, :, :, non_zero_filters]\n",
    "            new_model_weights=non_zero_weights[:,:,res5a_branch2a_layer_input_channel,:]\n",
    "            non_zero_biases = weights[1][non_zero_filters]\n",
    "            new_layer.set_weights([new_model_weights,non_zero_biases])\n",
    "            bn_layer_index=model.layers.index(layer) + 2\n",
    "            weights=model.layers[bn_layer_index].get_weights()\n",
    "            pruned_bn_layer_index=pruned_model.layers.index(new_layer) + 2\n",
    "            bn_weights=[]\n",
    "            bn_weights=[weights[0][non_zero_filters],weights[1][non_zero_filters],weights[2][non_zero_filters],weights[3][non_zero_filters]]\n",
    "            pruned_model.layers[pruned_bn_layer_index].set_weights(bn_weights)\n",
    "            \n",
    "    if isinstance(layer,Dense):\n",
    "        dense_weights=layer.get_weights()\n",
    "        new_dense_weight=dense_weights[0][previous_layer_input_channel]\n",
    "                #new_dense_bias=dense_weights[1][previous_layer_input_channel]\n",
    "        new_layer.set_weights([new_dense_weight,dense_weights[1]])\n",
    "\n",
    "    \n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return 0.001 * (0.5 ** (epoch // 10))\n",
    "    reduce_lr = LearningRateScheduler(lr_scheduler)\n",
    "    \n",
    "    \n",
    "    # For a multi-class classification problem\n",
    "    pruned_model.compile(loss='sparse_categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n",
    "     #Finetune\n",
    "    \n",
    "    history = pruned_model.fit(train_X, training_labels, epochs=35, validation_data = (valid_X, validation_labels), batch_size=16,callbacks=[reduce_lr ])\n",
    "    \n",
    "    #model evaluation\n",
    "    model_loss, pruned_accuracy = pruned_model.evaluate(valid_X, validation_labels, verbose=1)\n",
    "    #print('Filter Pruned test accuracy:', pruned_accuracy)\n",
    "    filter_pruned_model_accuracy.append(pruned_accuracy)\n",
    "    print(filter_pruned_model_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Total number of parameters before pruning: {model.count_params()}\")\n",
    "    print(f\"Total number of parameters after pruning: {pruned_model.count_params()}\")\n",
    "    \n",
    "    number_of_parameters_after_pruning.append(pruned_model.count_params())\n",
    "    print(number_of_parameters_after_pruning)\n",
    "    print(f'Pruned percentage: {(1-(pruned_model.count_params()/model.count_params()))*100}')\n",
    "\n",
    "    del pruned_model\n",
    "    gc.collect() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG+STD Max GN CIFAR-10\n",
    "[0.8894000053405762, 0.8805000185966492, 0.8730999827384949, 0.8808000087738037, 0.8805000185966492, 0.8723000288009644, 0.8697999715805054, 0.8604999780654907]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "\n",
    "AVG   Max  FC CIFAR-10 \n",
    "[0.8899999856948853, 0.8795999884605408, 0.880299985408783, 0.880299985408783, 0.8790000081062317, 0.8794999718666077, 0.867900013923645, 0.8583999872207642]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "\n",
    "AVG+STD Max FC CIFAR-10\n",
    "\n",
    "[0.8748000264167786, 0.8680999875068665, 0.8676000237464905, 0.8669000267982483, 0.8633000254631042, 0.8658000230789185, 0.8529999852180481, 0.8384000062942505]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "    \n",
    "STD Max FC CIFAR-10\n",
    "[0.8701000213623047, 0.8637999892234802, 0.8686000108718872, 0.8621000051498413, 0.8615999817848206, 0.8593999743461609, 0.845300018787384, 0.8464000225067139]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "    \n",
    " STD Max GN CIFAR-10   \n",
    "[0.8851000070571899, 0.8716999888420105, 0.8774999976158142, 0.868399977684021, 0.8600999712944031, 0.869700014591217, 0.8610000014305115, 0.8562999963760376]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "    \n",
    "STD AVG GN CIFAR-10 \n",
    "[0.8880000114440918, 0.8858000040054321, 0.8733999729156494, 0.876800000667572, 0.8777999877929688, 0.8725000023841858, 0.864799976348877, 0.8607000112533569]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    "    \n",
    "STD AVG FC CIFAR-10 \n",
    "\n",
    "[0.8747000098228455, 0.8784000277519226, 0.8605999946594238, 0.8751999735832214, 0.866599977016449, 0.8583999872207642, 0.8547000288963318, 0.8435999751091003]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    " \n",
    "AVG+STD Max+STD FC CIFAR-10   \n",
    " \n",
    "[0.8805999755859375, 0.8797000050544739, 0.868399977684021, 0.8680999875068665, 0.866100013256073, 0.8607000112533569, 0.8586000204086304, 0.8428000211715698]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957\n",
    " AVG+STD Max+STD GN CIFAR-10      \n",
    "[0.8744999766349792, 0.8751000165939331, 0.8745999932289124, 0.8697999715805054, 0.8747000098228455, 0.8697999715805054, 0.8658999800682068, 0.8607000112533569]\n",
    "Total number of parameters before pruning: 23608202\n",
    "Total number of parameters after pruning: 994866\n",
    "[19185418, 15175223, 11655794, 8582407, 5952714, 3847402, 2183191, 994866]\n",
    "Pruned percentage: 95.78593066934957"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
